"use strict";(self.webpackChunkkaito_website=self.webpackChunkkaito_website||[]).push([[3719],{28453:(e,t,n)=>{n.d(t,{R:()=>o,x:()=>d});var s=n(96540);const r={},i=s.createContext(r);function o(e){const t=s.useContext(i);return s.useMemo((function(){return"function"==typeof e?e(t):{...t,...e}}),[t,e])}function d(e){let t;return t=e.disableParentContext?"function"==typeof e.components?e.components(r):e.components||r:o(e.components),s.createElement(i.Provider,{value:t},e.children)}},93689:(e,t,n)=>{n.r(t),n.d(t,{assets:()=>c,contentTitle:()=>d,default:()=>h,frontMatter:()=>o,metadata:()=>s,toc:()=>a});const s=JSON.parse('{"id":"presets","title":"Presets","description":"Best-effort Hugging Face vLLM model support","source":"@site/docs/presets.md","sourceDirName":".","slug":"/presets","permalink":"/kaito/docs/next/presets","draft":false,"unlisted":false,"editUrl":"https://github.com/kaito-project/kaito/tree/main/website/docs/presets.md","tags":[],"version":"current","frontMatter":{"title":"Presets"},"sidebar":"sidebar","previous":{"title":"Quick Start","permalink":"/kaito/docs/next/quick-start"},"next":{"title":"Usage","permalink":"/kaito/docs/next/usage"}}');var r=n(74848),i=n(28453);const o={title:"Presets"},d=void 0,c={},a=[{value:"Validation",id:"validation",level:2},{value:"Distributed inference",id:"distributed-inference",level:2}];function l(e){const t={a:"a",admonition:"admonition",code:"code",h2:"h2",p:"p",pre:"pre",strong:"strong",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",...(0,i.R)(),...e.components};return(0,r.jsxs)(r.Fragment,{children:[(0,r.jsxs)(t.admonition,{title:"What's NEW!",type:"info",children:[(0,r.jsx)(t.p,{children:(0,r.jsx)(t.strong,{children:"Best-effort Hugging Face vLLM model support"})}),(0,r.jsxs)(t.p,{children:["Starting from KAITO v0.9.0, generic Hugging Face models are supported on a best-effort basis. By specifying a Hugging Face model card ID as ",(0,r.jsx)(t.code,{children:"inference.preset.name"})," in the KAITO workspace or InferenceSet configuration, you can run any Hugging Face model with a model architecture supported by vLLM on KAITO. In this process, KAITO retrieves the model metadata from the Hugging Face website and generates model preset configurations by analyzing this data. During the creation of vLLM inference workloads, KAITO downloads the model weights directly from the Hugging Face site. Below is an example illustrating how to create a Hugging Face inference workload using the model card ID ",(0,r.jsx)(t.code,{children:"Qwen/Qwen3-0.6B"})," from ",(0,r.jsx)(t.a,{href:"https://huggingface.co/Qwen/Qwen3-0.6B",children:"https://huggingface.co/Qwen/Qwen3-0.6B"}),":"]}),(0,r.jsx)(t.admonition,{type:"tip",children:(0,r.jsxs)(t.p,{children:["For certain Hugging Face models that require authentication, configure ",(0,r.jsx)(t.code,{children:"inference.preset.presetOptions.modelAccessSecret"})," to reference a Secret containing a Hugging Face access token under the ",(0,r.jsx)(t.code,{children:"HF_TOKEN"})," key."]})})]}),"\n",(0,r.jsx)(t.pre,{children:(0,r.jsx)(t.code,{className:"language-yaml",children:"apiVersion: kaito.sh/v1beta1\nkind: Workspace\nmetadata:\n  name: qwen3-06b\nresource:\n  instanceType: Standard_NC24ads_A100_v4\n  labelSelector:\n    matchLabels:\n      apps: qwen3-06b\ninference:\n  preset:\n    name: Qwen/Qwen3-0.6B\n"})}),"\n",(0,r.jsx)(t.p,{children:":::"}),"\n",(0,r.jsx)(t.p,{children:"The current supported built-in model families with preset configurations are listed below."}),"\n",(0,r.jsxs)(t.table,{children:[(0,r.jsx)(t.thead,{children:(0,r.jsxs)(t.tr,{children:[(0,r.jsx)(t.th,{children:"Model Family"}),(0,r.jsx)(t.th,{children:"Compatible KAITO Versions"})]})}),(0,r.jsxs)(t.tbody,{children:[(0,r.jsxs)(t.tr,{children:[(0,r.jsx)(t.td,{children:(0,r.jsx)(t.a,{href:"https://github.com/kaito-project/kaito/tree/main/presets/workspace/models/deepseek",children:"deepseek"})}),(0,r.jsx)(t.td,{children:"v0.6.0+"})]}),(0,r.jsxs)(t.tr,{children:[(0,r.jsx)(t.td,{children:(0,r.jsx)(t.a,{href:"https://github.com/kaito-project/kaito/tree/main/presets/workspace/models/falcon",children:"falcon"})}),(0,r.jsx)(t.td,{children:"v0.0.1+"})]}),(0,r.jsxs)(t.tr,{children:[(0,r.jsx)(t.td,{children:(0,r.jsx)(t.a,{href:"https://github.com/kaito-project/kaito/tree/main/presets/workspace/models/gemma3",children:"gemma-3"})}),(0,r.jsx)(t.td,{children:"v0.8.0+"})]}),(0,r.jsxs)(t.tr,{children:[(0,r.jsx)(t.td,{children:(0,r.jsx)(t.a,{href:"https://github.com/kaito-project/kaito/tree/main/presets/workspace/models/gpt",children:"gpt-oss"})}),(0,r.jsx)(t.td,{children:"v0.7.0+"})]}),(0,r.jsxs)(t.tr,{children:[(0,r.jsx)(t.td,{children:(0,r.jsx)(t.a,{href:"https://github.com/kaito-project/kaito/tree/main/presets/workspace/models/llama",children:"llama"})}),(0,r.jsx)(t.td,{children:"v0.4.6+"})]}),(0,r.jsxs)(t.tr,{children:[(0,r.jsx)(t.td,{children:(0,r.jsx)(t.a,{href:"https://github.com/kaito-project/kaito/tree/main/presets/workspace/models/mistral",children:"mistral"})}),(0,r.jsx)(t.td,{children:"v0.2.0+"})]}),(0,r.jsxs)(t.tr,{children:[(0,r.jsx)(t.td,{children:(0,r.jsx)(t.a,{href:"https://github.com/kaito-project/kaito/tree/main/presets/workspace/models/phi3",children:"phi-3"})}),(0,r.jsx)(t.td,{children:"v0.3.0+"})]}),(0,r.jsxs)(t.tr,{children:[(0,r.jsx)(t.td,{children:(0,r.jsx)(t.a,{href:"https://github.com/kaito-project/kaito/tree/main/presets/workspace/models/phi4",children:"phi-4"})}),(0,r.jsx)(t.td,{children:"v0.4.5+"})]}),(0,r.jsxs)(t.tr,{children:[(0,r.jsx)(t.td,{children:(0,r.jsx)(t.a,{href:"https://github.com/kaito-project/kaito/tree/main/presets/workspace/models/qwen",children:"qwen"})}),(0,r.jsx)(t.td,{children:"v0.4.1+"})]})]})]}),"\n",(0,r.jsx)(t.h2,{id:"validation",children:"Validation"}),"\n",(0,r.jsxs)(t.p,{children:["Each preset built-in model has its own hardware requirements in terms of GPU count and GPU memory defined in the respective ",(0,r.jsx)(t.code,{children:"model.go"})," file. KAITO controller performs a validation check of whether the specified SKU and node count are sufficient to run the model or not. In case the provided SKU is not in the known list, the controller bypasses the validation check which means users need to ensure the model can run with the provided SKU."]}),"\n",(0,r.jsx)(t.h2,{id:"distributed-inference",children:"Distributed inference"}),"\n",(0,r.jsxs)(t.p,{children:["For models that support distributed inference, when the node count is larger than one, ",(0,r.jsx)(t.a,{href:"https://pytorch.org/docs/stable/distributed.elastic.html",children:"Torch Distributed Elastic"})," is configured with master/worker pods running in multiple nodes and the service endpoint is the master pod."]}),"\n",(0,r.jsx)(t.p,{children:"The following preset models support multi-node distributed inference:"}),"\n",(0,r.jsxs)(t.table,{children:[(0,r.jsx)(t.thead,{children:(0,r.jsxs)(t.tr,{children:[(0,r.jsx)(t.th,{children:"Model Family"}),(0,r.jsx)(t.th,{children:"Models"}),(0,r.jsx)(t.th,{children:"Multi-Node Support"})]})}),(0,r.jsxs)(t.tbody,{children:[(0,r.jsxs)(t.tr,{children:[(0,r.jsx)(t.td,{children:(0,r.jsx)(t.a,{href:"https://github.com/kaito-project/kaito/tree/main/presets/workspace/models/deepseek",children:"deepseek"})}),(0,r.jsxs)(t.td,{children:[(0,r.jsx)(t.code,{children:"deepseek-r1"}),", ",(0,r.jsx)(t.code,{children:"deepseek-v3"})]}),(0,r.jsx)(t.td,{children:"\u2705"})]}),(0,r.jsxs)(t.tr,{children:[(0,r.jsx)(t.td,{children:(0,r.jsx)(t.a,{href:"https://github.com/kaito-project/kaito/tree/main/presets/workspace/models/llama",children:"llama"})}),(0,r.jsx)(t.td,{children:(0,r.jsx)(t.code,{children:"llama-3.3-70b-instruct"})}),(0,r.jsx)(t.td,{children:"\u2705"})]})]})]}),"\n",(0,r.jsxs)(t.p,{children:["For detailed information on configuring and using multi-node inference, see the ",(0,r.jsx)(t.a,{href:"/kaito/docs/next/multi-node-inference",children:"Multi-Node Inference"})," documentation."]})]})}function h(e={}){const{wrapper:t}={...(0,i.R)(),...e.components};return t?(0,r.jsx)(t,{...e,children:(0,r.jsx)(l,{...e})}):l(e)}}}]);